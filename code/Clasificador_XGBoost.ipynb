{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner](https://github.com/paulguz261/MIAD_20242_proyecto_despliegue_aplicaciones/blob/main/docs/images/despliegue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "import mlflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1  Female  61.0             0              0          Yes  Self-employed   \n",
       "2    Male  80.0             0              1          Yes        Private   \n",
       "3  Female  49.0             0              0          Yes        Private   \n",
       "4  Female  79.0             1              0          Yes  Self-employed   \n",
       "\n",
       "  Residence_type  avg_glucose_level        bmi   smoking_status  stroke  \n",
       "0          Urban             228.69  36.600000  formerly smoked       1  \n",
       "1          Rural             202.21  28.893237     never smoked       1  \n",
       "2          Rural             105.92  32.500000     never smoked       1  \n",
       "3          Urban             171.23  34.400000           smokes       1  \n",
       "4          Rural             174.12  24.000000     never smoked       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/clean/personas_limpio.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que las variables binarias quedaron como númericas, se procede a convertirlas de nuevo\n",
    "def convert_to_categorical(df, columns):\n",
    "    \"\"\"\n",
    "    Convierte las columnas especificadas de un DataFrame a tipo categórico.\n",
    "\n",
    "    Parámetros:\n",
    "    df (pd.DataFrame): El DataFrame en el que se realizarán las conversiones.\n",
    "    columns (list): Lista de nombres de columnas a convertir a tipo categórico.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: El DataFrame con las columnas especificadas convertidas a tipo categórico.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = pd.Categorical(df[column])\n",
    "        else:\n",
    "            print(f\"Columna '{column}' no encontrada en el DataFrame.\")\n",
    "    return df\n",
    "\n",
    "categorical_columns = ['hypertension', 'heart_disease','stroke']\n",
    "data = convert_to_categorical(data, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   gender             5110 non-null   object  \n",
      " 1   age                5110 non-null   float64 \n",
      " 2   hypertension       5110 non-null   category\n",
      " 3   heart_disease      5110 non-null   category\n",
      " 4   ever_married       5110 non-null   object  \n",
      " 5   work_type          5110 non-null   object  \n",
      " 6   Residence_type     5110 non-null   object  \n",
      " 7   avg_glucose_level  5110 non-null   float64 \n",
      " 8   bmi                5110 non-null   float64 \n",
      " 9   smoking_status     5110 non-null   object  \n",
      " 10  stroke             5110 non-null   category\n",
      "dtypes: category(3), float64(3), object(5)\n",
      "memory usage: 334.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos `personas_limpio`contiene 5.110 registros y 11 columnas resultado de la limpieza de datos aplicada. Las variables categóricas son `gender`, `ever_married`, `work_type`, `resident_type`y `smoking_status`, variables que indican factores importantes a la hora de predecir un ACV. Además, las variables númericas tales `age`, `avg_glucose_level` y `bmi` indican edad y estado de salud de la persona. Y las variables binarias `hypertension` y `heart_disase`, las cuales indican el padecimiento de cierta patologia. Finalmente, la variable a predecir `stroke` indica la presencia de ACV en la persona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se definen las variables predictoras y a predecir, se codifican las variables categoricas aplicando One-Hot Encoding para transformarlas en variables númericas y se aplica reducción de dimensionalidad con PCA. Además, se divide el conjunto de datos en entrenamiento y prueba para la construcción y prueba de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0    4861\n",
       "1     249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las variables predictoras y a predecir\n",
    "X = data.drop(columns=['stroke'])  # Eliminar variable a predecir\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de variables categoricas a numericas con One-Hot Encoding\n",
    "data_dummies = pd.get_dummies(X,columns=X.select_dtypes(include=['object','category']).columns.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que la clase a predecir esta desbalanceada, hay mayor proporción de registros de personas aun no han presentado un ACV, se probara técnicas de balanceo de clases antes de aplicar modelos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(X,y,tecnica='SMOTE'):\n",
    "    \"\"\"\n",
    "    Aplica diversas tecnicas de balanceo de clases.\n",
    "\n",
    "    Parámetros:\n",
    "    X: variables predictoras.\n",
    "    y: variable a predecir.\n",
    "    técnica: método a aplicar de balanceo de clases.\n",
    "\n",
    "    Retorna:\n",
    "    X_resampled: variables predictoras resampleadas.\n",
    "    y_resampled: variable a predecir resampleada.\n",
    "    \"\"\"\n",
    "    if tecnica == 'SMOTE':\n",
    "        \n",
    "        # Oversampling con SMOTE\n",
    "        smote = SMOTE(sampling_strategy='minority')  # Aumenta solo la clase minoritaria\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    if tecnica == 'Undersampling':\n",
    "\n",
    "        # Undersampling con RandomUnderSampler\n",
    "        undersample = RandomUnderSampler(sampling_strategy=0.5)  # Reduce la clase mayoritaria a una proporción de 0.5\n",
    "        X_resampled, y_resampled = undersample.fit_resample(X, y)\n",
    "\n",
    "    if tecnica == 'SMOTE-ENN':\n",
    "\n",
    "        # Combinación de SMOTE y ENN(Edicion de vecinos)\n",
    "        smote_enn = SMOTEENN(sampling_strategy='auto')\n",
    "        X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "    return X_resampled, y_resampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = class_balance(data_dummies, y, 'Undersampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0    498\n",
       "1    249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de las variables\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones antes de PCA: (747, 23)\n",
      "Dimensiones después de PCA: (747, 13)\n"
     ]
    }
   ],
   "source": [
    "# Reducción de dimensionalidad PCA\n",
    "pca = PCA(n_components=0.95)  # COnservar el 95% de la varianza\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "print(f\"Dimensiones antes de PCA: {data_scaled.shape}\")\n",
    "print(f\"Dimensiones después de PCA: {data_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_pca, y_resampled, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se realizara el ajuste de hiperparametros en cada uno de los modelos de clasificación probados, los mejores hiperparametros seran almacenados en MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5454545454545454, 0.7368421052631579)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo básico\n",
    "clf = XGBClassifier()\n",
    "# Entrenamiento (fit) y desempeño del modelo XGBClassifier\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usara una funcion para hacer la busqueda de los mejores hiperparametros de manera automática\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Retorna: Métrica del modelo de clasificación\n",
    "    \"\"\"\n",
    "    # Hiperparametros a probar \n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'binary:logistic',  # Clasificación binaria\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 8),\n",
    "        'reg_lambda' : trial.suggest_int('reg_lambda',1, 10),\n",
    "        'reg_alpha' : trial.suggest_int('reg_alpha',1, 10)\n",
    "    }\n",
    "\n",
    "    # Crear y entrenar el modelo\n",
    "    clf = XGBClassifier(**param)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir sobre el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular metricas\n",
    "    acc = metrics.accuracy_score(y_pred, y_test.values)\n",
    "    f1_score = metrics.f1_score(y_pred, y_test.values)\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-09 11:32:47,301] A new study created in memory with name: no-name-9549bb5f-d7e1-4107-a42e-aa01ce5ce459\n",
      "[I 2024-11-09 11:32:47,736] Trial 0 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.03207199868750234, 'subsample': 0.7724632807415478, 'colsample_bytree': 0.7687759982194762, 'min_child_weight': 4, 'reg_lambda': 6, 'reg_alpha': 9}. Best is trial 0 with value: 0.5333333333333333.\n",
      "[I 2024-11-09 11:32:48,320] Trial 1 finished with value: 0.5352112676056338 and parameters: {'n_estimators': 321, 'max_depth': 8, 'learning_rate': 0.06001778287786115, 'subsample': 0.8158876167388461, 'colsample_bytree': 0.9048253277361381, 'min_child_weight': 4, 'reg_lambda': 7, 'reg_alpha': 6}. Best is trial 1 with value: 0.5352112676056338.\n",
      "[I 2024-11-09 11:32:48,620] Trial 2 finished with value: 0.5507246376811594 and parameters: {'n_estimators': 280, 'max_depth': 2, 'learning_rate': 0.09182747429146504, 'subsample': 0.8910168127829313, 'colsample_bytree': 0.9265553860316288, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:48,997] Trial 3 finished with value: 0.5217391304347826 and parameters: {'n_estimators': 446, 'max_depth': 3, 'learning_rate': 0.05621146377734887, 'subsample': 0.7690146135644385, 'colsample_bytree': 0.7153992429023329, 'min_child_weight': 7, 'reg_lambda': 1, 'reg_alpha': 10}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:49,641] Trial 4 finished with value: 0.5277777777777778 and parameters: {'n_estimators': 327, 'max_depth': 9, 'learning_rate': 0.08849289466938563, 'subsample': 0.8047754660028806, 'colsample_bytree': 0.93588619875126, 'min_child_weight': 4, 'reg_lambda': 5, 'reg_alpha': 3}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:50,256] Trial 5 finished with value: 0.5390070921985816 and parameters: {'n_estimators': 472, 'max_depth': 10, 'learning_rate': 0.06391283086812587, 'subsample': 0.8863196341475493, 'colsample_bytree': 0.9314714108112322, 'min_child_weight': 5, 'reg_lambda': 6, 'reg_alpha': 8}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:51,222] Trial 6 finished with value: 0.5205479452054794 and parameters: {'n_estimators': 385, 'max_depth': 7, 'learning_rate': 0.04019529725731923, 'subsample': 0.8186752426747794, 'colsample_bytree': 0.7311995452253979, 'min_child_weight': 4, 'reg_lambda': 4, 'reg_alpha': 2}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:51,722] Trial 7 finished with value: 0.547945205479452 and parameters: {'n_estimators': 306, 'max_depth': 4, 'learning_rate': 0.0821523712784953, 'subsample': 0.8743870804931746, 'colsample_bytree': 0.8900533715255137, 'min_child_weight': 3, 'reg_lambda': 8, 'reg_alpha': 2}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:52,028] Trial 8 finished with value: 0.4925373134328358 and parameters: {'n_estimators': 116, 'max_depth': 9, 'learning_rate': 0.051829503169070465, 'subsample': 0.9623825451555126, 'colsample_bytree': 0.7158784166231718, 'min_child_weight': 5, 'reg_lambda': 1, 'reg_alpha': 2}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:53,323] Trial 9 finished with value: 0.5492957746478874 and parameters: {'n_estimators': 462, 'max_depth': 10, 'learning_rate': 0.021825367661321787, 'subsample': 0.7161223498053901, 'colsample_bytree': 0.8492232597976361, 'min_child_weight': 3, 'reg_lambda': 9, 'reg_alpha': 1}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:53,526] Trial 10 finished with value: 0.48120300751879697 and parameters: {'n_estimators': 205, 'max_depth': 1, 'learning_rate': 0.09834989162484167, 'subsample': 0.9564833139281315, 'colsample_bytree': 0.9943503284124161, 'min_child_weight': 1, 'reg_lambda': 10, 'reg_alpha': 5}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:54,376] Trial 11 finished with value: 0.5230769230769231 and parameters: {'n_estimators': 402, 'max_depth': 6, 'learning_rate': 0.01595095548831088, 'subsample': 0.7268462703649009, 'colsample_bytree': 0.8270457683848366, 'min_child_weight': 2, 'reg_lambda': 9, 'reg_alpha': 5}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:54,576] Trial 12 finished with value: 0.5238095238095238 and parameters: {'n_estimators': 214, 'max_depth': 1, 'learning_rate': 0.015189063603881073, 'subsample': 0.918576213276856, 'colsample_bytree': 0.8297965504894996, 'min_child_weight': 6, 'reg_lambda': 10, 'reg_alpha': 7}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:54,879] Trial 13 finished with value: 0.5416666666666666 and parameters: {'n_estimators': 260, 'max_depth': 3, 'learning_rate': 0.07445633360769774, 'subsample': 0.9989079134295261, 'colsample_bytree': 0.8520711906569219, 'min_child_weight': 2, 'reg_lambda': 8, 'reg_alpha': 4}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:55,126] Trial 14 finished with value: 0.5179856115107914 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.0367242811731674, 'subsample': 0.7171274194239962, 'colsample_bytree': 0.9957637115548851, 'min_child_weight': 8, 'reg_lambda': 8, 'reg_alpha': 1}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:55,522] Trial 15 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 500, 'max_depth': 2, 'learning_rate': 0.028042159803265836, 'subsample': 0.8679850821442022, 'colsample_bytree': 0.78500036805718, 'min_child_weight': 2, 'reg_lambda': 3, 'reg_alpha': 7}. Best is trial 2 with value: 0.5507246376811594.\n",
      "[I 2024-11-09 11:32:56,116] Trial 16 finished with value: 0.5633802816901409 and parameters: {'n_estimators': 375, 'max_depth': 6, 'learning_rate': 0.047666154118774014, 'subsample': 0.9048688522043906, 'colsample_bytree': 0.873914066675995, 'min_child_weight': 3, 'reg_lambda': 9, 'reg_alpha': 4}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:32:56,619] Trial 17 finished with value: 0.5072463768115942 and parameters: {'n_estimators': 370, 'max_depth': 5, 'learning_rate': 0.04858566288930157, 'subsample': 0.9135234084049002, 'colsample_bytree': 0.9512949497154071, 'min_child_weight': 6, 'reg_lambda': 10, 'reg_alpha': 4}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:32:57,038] Trial 18 finished with value: 0.5285714285714286 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.06976706417751247, 'subsample': 0.9112924487491284, 'colsample_bytree': 0.8851064368442966, 'min_child_weight': 3, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:32:57,681] Trial 19 finished with value: 0.5379310344827586 and parameters: {'n_estimators': 348, 'max_depth': 4, 'learning_rate': 0.09690171396758165, 'subsample': 0.8424936586789589, 'colsample_bytree': 0.963699003773403, 'min_child_weight': 1, 'reg_lambda': 7, 'reg_alpha': 4}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:32:58,253] Trial 20 finished with value: 0.5428571428571428 and parameters: {'n_estimators': 426, 'max_depth': 7, 'learning_rate': 0.04379230922526934, 'subsample': 0.9526456049325355, 'colsample_bytree': 0.9107084649825546, 'min_child_weight': 6, 'reg_lambda': 7, 'reg_alpha': 7}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:32:59,342] Trial 21 finished with value: 0.5531914893617021 and parameters: {'n_estimators': 425, 'max_depth': 8, 'learning_rate': 0.022644691010864908, 'subsample': 0.8431855937956134, 'colsample_bytree': 0.8563934822288307, 'min_child_weight': 3, 'reg_lambda': 9, 'reg_alpha': 1}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:00,366] Trial 22 finished with value: 0.5492957746478874 and parameters: {'n_estimators': 409, 'max_depth': 7, 'learning_rate': 0.02858282546532756, 'subsample': 0.8463759038997297, 'colsample_bytree': 0.8708025541387402, 'min_child_weight': 3, 'reg_lambda': 9, 'reg_alpha': 3}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:01,276] Trial 23 finished with value: 0.5454545454545454 and parameters: {'n_estimators': 368, 'max_depth': 8, 'learning_rate': 0.0801900290456746, 'subsample': 0.8933299918445672, 'colsample_bytree': 0.7981525714550909, 'min_child_weight': 2, 'reg_lambda': 8, 'reg_alpha': 3}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:01,918] Trial 24 finished with value: 0.5594405594405595 and parameters: {'n_estimators': 290, 'max_depth': 8, 'learning_rate': 0.06921080492285506, 'subsample': 0.926912271950035, 'colsample_bytree': 0.8616811265673601, 'min_child_weight': 5, 'reg_lambda': 10, 'reg_alpha': 5}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:02,556] Trial 25 finished with value: 0.5428571428571428 and parameters: {'n_estimators': 347, 'max_depth': 8, 'learning_rate': 0.06835429547888024, 'subsample': 0.9371857675363324, 'colsample_bytree': 0.8661114779600768, 'min_child_weight': 5, 'reg_lambda': 10, 'reg_alpha': 5}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:03,377] Trial 26 finished with value: 0.5492957746478874 and parameters: {'n_estimators': 431, 'max_depth': 9, 'learning_rate': 0.04752313816575243, 'subsample': 0.8610052118786793, 'colsample_bytree': 0.8204274608108737, 'min_child_weight': 3, 'reg_lambda': 10, 'reg_alpha': 4}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:03,926] Trial 27 finished with value: 0.4806201550387597 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.010989029140228208, 'subsample': 0.9784856901891986, 'colsample_bytree': 0.8061493701134577, 'min_child_weight': 5, 'reg_lambda': 7, 'reg_alpha': 1}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:04,450] Trial 28 finished with value: 0.5035971223021583 and parameters: {'n_estimators': 347, 'max_depth': 7, 'learning_rate': 0.05746436492213032, 'subsample': 0.9315138533090013, 'colsample_bytree': 0.7557223962898072, 'min_child_weight': 8, 'reg_lambda': 5, 'reg_alpha': 3}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:04,801] Trial 29 finished with value: 0.5147058823529411 and parameters: {'n_estimators': 243, 'max_depth': 8, 'learning_rate': 0.03463746123995603, 'subsample': 0.7798646398305497, 'colsample_bytree': 0.8452707933358863, 'min_child_weight': 7, 'reg_lambda': 6, 'reg_alpha': 9}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:05,146] Trial 30 finished with value: 0.5116279069767442 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.022585538387075364, 'subsample': 0.8427882343179585, 'colsample_bytree': 0.878579617156559, 'min_child_weight': 3, 'reg_lambda': 3, 'reg_alpha': 8}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:05,586] Trial 31 finished with value: 0.5571428571428572 and parameters: {'n_estimators': 288, 'max_depth': 9, 'learning_rate': 0.0870755825248918, 'subsample': 0.9110022079644403, 'colsample_bytree': 0.9083661187751213, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 16 with value: 0.5633802816901409.\n",
      "[I 2024-11-09 11:33:06,076] Trial 32 finished with value: 0.5815602836879432 and parameters: {'n_estimators': 312, 'max_depth': 9, 'learning_rate': 0.07750717067598396, 'subsample': 0.9090846258458242, 'colsample_bytree': 0.8953684736307495, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:06,998] Trial 33 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 312, 'max_depth': 10, 'learning_rate': 0.07998614914495207, 'subsample': 0.9052757787309966, 'colsample_bytree': 0.906722001894206, 'min_child_weight': 4, 'reg_lambda': 8, 'reg_alpha': 5}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:07,521] Trial 34 finished with value: 0.5352112676056338 and parameters: {'n_estimators': 242, 'max_depth': 9, 'learning_rate': 0.08770747155697606, 'subsample': 0.9355563026596374, 'colsample_bytree': 0.8971652553538495, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:08,031] Trial 35 finished with value: 0.5217391304347826 and parameters: {'n_estimators': 282, 'max_depth': 9, 'learning_rate': 0.06316965755805157, 'subsample': 0.8928427288396161, 'colsample_bytree': 0.9165081948847725, 'min_child_weight': 5, 'reg_lambda': 10, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:08,456] Trial 36 finished with value: 0.5428571428571428 and parameters: {'n_estimators': 334, 'max_depth': 10, 'learning_rate': 0.07363207437371723, 'subsample': 0.979092930951708, 'colsample_bytree': 0.9485946685770561, 'min_child_weight': 4, 'reg_lambda': 8, 'reg_alpha': 7}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:08,847] Trial 37 finished with value: 0.5151515151515151 and parameters: {'n_estimators': 306, 'max_depth': 7, 'learning_rate': 0.08471918568114423, 'subsample': 0.9274676090061602, 'colsample_bytree': 0.8933445394186637, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 8}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:09,339] Trial 38 finished with value: 0.5109489051094891 and parameters: {'n_estimators': 324, 'max_depth': 8, 'learning_rate': 0.09041510856655187, 'subsample': 0.8837374932748011, 'colsample_bytree': 0.9242990853991337, 'min_child_weight': 6, 'reg_lambda': 10, 'reg_alpha': 5}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:09,854] Trial 39 finished with value: 0.5285714285714286 and parameters: {'n_estimators': 377, 'max_depth': 9, 'learning_rate': 0.06124018169858625, 'subsample': 0.9452764150234185, 'colsample_bytree': 0.9675231016231721, 'min_child_weight': 5, 'reg_lambda': 7, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:10,401] Trial 40 finished with value: 0.5277777777777778 and parameters: {'n_estimators': 294, 'max_depth': 10, 'learning_rate': 0.07652937546064989, 'subsample': 0.8240998250538794, 'colsample_bytree': 0.9346383060393353, 'min_child_weight': 4, 'reg_lambda': 8, 'reg_alpha': 4}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:11,141] Trial 41 finished with value: 0.5390070921985816 and parameters: {'n_estimators': 309, 'max_depth': 10, 'learning_rate': 0.0799180205954578, 'subsample': 0.902144831013737, 'colsample_bytree': 0.9048034927731285, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 5}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:11,746] Trial 42 finished with value: 0.5390070921985816 and parameters: {'n_estimators': 276, 'max_depth': 9, 'learning_rate': 0.06698795053102777, 'subsample': 0.9078024933990466, 'colsample_bytree': 0.8710503495042482, 'min_child_weight': 4, 'reg_lambda': 8, 'reg_alpha': 5}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:12,216] Trial 43 finished with value: 0.49635036496350365 and parameters: {'n_estimators': 322, 'max_depth': 10, 'learning_rate': 0.09426356142225861, 'subsample': 0.8767873468306885, 'colsample_bytree': 0.9120738283323413, 'min_child_weight': 5, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:12,721] Trial 44 finished with value: 0.5428571428571428 and parameters: {'n_estimators': 247, 'max_depth': 9, 'learning_rate': 0.08635491278998202, 'subsample': 0.9706260279137613, 'colsample_bytree': 0.8405329543911376, 'min_child_weight': 4, 'reg_lambda': 10, 'reg_alpha': 5}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:13,246] Trial 45 finished with value: 0.5492957746478874 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.07737887512974499, 'subsample': 0.9191549889599874, 'colsample_bytree': 0.8869370309170228, 'min_child_weight': 3, 'reg_lambda': 6, 'reg_alpha': 4}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:13,699] Trial 46 finished with value: 0.5401459854014599 and parameters: {'n_estimators': 224, 'max_depth': 8, 'learning_rate': 0.07171389760390817, 'subsample': 0.9005004885102615, 'colsample_bytree': 0.8613629523483429, 'min_child_weight': 5, 'reg_lambda': 8, 'reg_alpha': 7}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:14,251] Trial 47 finished with value: 0.5694444444444444 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.08374349476811342, 'subsample': 0.8677600612125366, 'colsample_bytree': 0.8985926574050886, 'min_child_weight': 4, 'reg_lambda': 9, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:14,728] Trial 48 finished with value: 0.5223880597014925 and parameters: {'n_estimators': 391, 'max_depth': 9, 'learning_rate': 0.0932782200635254, 'subsample': 0.860988877713709, 'colsample_bytree': 0.877152107906731, 'min_child_weight': 2, 'reg_lambda': 9, 'reg_alpha': 8}. Best is trial 32 with value: 0.5815602836879432.\n",
      "[I 2024-11-09 11:33:15,251] Trial 49 finished with value: 0.5390070921985816 and parameters: {'n_estimators': 362, 'max_depth': 6, 'learning_rate': 0.05397025866818917, 'subsample': 0.8826676765192187, 'colsample_bytree': 0.8359752641081928, 'min_child_weight': 6, 'reg_lambda': 10, 'reg_alpha': 6}. Best is trial 32 with value: 0.5815602836879432.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 487,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.026963817891748128,\n",
       " 'subsample': 0.7092093034163246,\n",
       " 'colsample_bytree': 0.7135770853831627,\n",
       " 'min_child_weight': 4,\n",
       " 'reg_lambda': 6,\n",
       " 'reg_alpha': 3}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar la URI de seguimiento de MLflow para que apunte al servidor local\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # La dirección IP y puerto del servidor MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función define una corrida del modelo, con entrenamiento y registro en MLflow\n",
    "def run_mlflow(run_name=\"MLflow CE XGBoost-Best trial\"):\n",
    "\n",
    "    # Iniciamos una corrida de MLflow\n",
    "    mlflow.start_run(run_name=run_name)\n",
    "    run = mlflow.active_run()\n",
    "    \n",
    "    # MLflow asigna un ID al experimento y a la corrida\n",
    "    experimentID = run.info.experiment_id\n",
    "    runID = run.info.run_uuid\n",
    "\n",
    "    # Entrenar el modelo con los mejores parametros\n",
    "    clf =  XGBClassifier(**study.best_trial.params)\n",
    "    y_pred = clf.fit(X_train, y_train)\n",
    "    # Evaluar el modelo\n",
    "    f1_score = metrics.f1_score(y_pred, y_test.values)\n",
    "\n",
    "    # Registrar los parametros y métrica\n",
    "    mlflow.log_params(study.best_trial.params)\n",
    "    mlflow.log_metric(\"f1_score\", study.best_trial.value)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(clf, \"xgboost-model\")\n",
    "\n",
    "    mlflow.end_run(status='FINISHED')\n",
    "    return (experimentID, runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_true' parameter of f1_score must be an array-like or a sparse matrix. Got XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8953684736307495, device=None,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, feature_types=None, gamma=None,\n              grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.07750717067598396,\n              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=9, max_leaves=None,\n              min_child_weight=4, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=312, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (experimentID, runID) \u001b[38;5;241m=\u001b[39m run_mlflow()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow Run completed with run_id \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and experiment_id \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(runID, experimentID))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "Cell \u001b[1;32mIn[64], line 16\u001b[0m, in \u001b[0;36mrun_mlflow\u001b[1;34m(run_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mf1_score(y_pred, y_test\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Registrar los parametros y métrica\u001b[39;00m\n\u001b[0;32m     19\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\sonia.olaya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 203\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    204\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    205\u001b[0m )\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\sonia.olaya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'y_true' parameter of f1_score must be an array-like or a sparse matrix. Got XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8953684736307495, device=None,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, feature_types=None, gamma=None,\n              grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.07750717067598396,\n              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=9, max_leaves=None,\n              min_child_weight=4, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=312, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...) instead."
     ]
    }
   ],
   "source": [
    "(experimentID, runID) = run_mlflow()\n",
    "print(\"MLflow Run completed with run_id {} and experiment_id {}\".format(runID, experimentID))\n",
    "print(tf.__version__)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/09 11:59:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run MLflow CE XGBoost-Best trial at: http://localhost:5000/#/experiments/0/runs/a37edfbd1f50483ca97b9f937788043b.\n",
      "2024/11/09 11:59:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
